# 🔒 Model Extraction Defense  

This repository provides implementations of key **defense strategies** against **model extraction attacks**, ensuring robustness against unauthorized model replication. Below are the baseline methods included:

## 🛡 Defense Baselines  

### 1️⃣ **MeCo: Defending Against Data-Free Model Extraction by Distributionally Robust Defensive Training**  
**Description:** MeCo employs **distributionally robust optimization (DRO)** to counter **data-free model extraction attacks**, making stolen models less effective.  
🔗 **Repository:** [MeCo GitHub](https://github.com/joey-wang123/DFME-DRO)  

### 2️⃣ **ACT: Defense Against Model Extraction Attack by Bayesian Active Watermarking**  
**Description:** ACT leverages **Bayesian active learning** to embed watermarks that detect and deter **model extraction attempts**.  
🔗 **Repository:** [ACT GitHub](https://github.com/joey-wang123/Bayes-Active-Watermark/tree/main)  

### 3️⃣ **DNF: Dynamic Neural Fortresses – An Adaptive Shield for Model Extraction Defense**  
**Description:** DNF dynamically **adapts neural networks** to disrupt adversarial extraction attempts, providing **an evolving defense mechanism**.  
🔗 **Repository:** [DNF GitHub](https://github.com/SYCodeShare/Dynamic-Neural-Fortresses)  

## 📌 **Usage**  
Each defense method is provided with its own **repository and implementation details**. Follow the respective links to explore the **code, setup instructions, and experimental results**.

## 📄 **Citing This Work**  
If you find these defenses useful, please consider citing the original papers and repositories.

## 🤝 **Contributions**  
We welcome **contributions and discussions**! If you have any suggestions or improvements, feel free to open an **issue** or submit a **pull request**.

---

This structure improves **clarity, readability, and engagement**, making it easier for users to understand the **purpose and significance** of each defense method. 🚀 Let me know if you need further refinements! 😊
